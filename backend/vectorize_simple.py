import asyncio
import sys
sys.path.insert(0, '/app')

from app.db.database import AsyncSessionLocal
from app.models.models import KnowledgeBaseChunk, VectorEmbeddingConfig
from pathlib import Path
import uuid
from datetime import datetime
import hashlib
import httpx

async def generate_embedding(text, config):
    """å•ä¸ªæ–‡æœ¬ç”ŸæˆåµŒå…¥"""
    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.post(
            f"{config.api_url}embeddings",
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {config.api_key}"
            },
            json={
                "model": config.model_id or "text-embedding-v3",
                "input": {
                    "texts": [text]
                },
                "parameters": {
                    "text_type": "document"
                }
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            if 'output' in result and 'embeddings' in result['output']:
                return result['output']['embeddings'][0]['embedding']
        else:
            print(f"  APIé”™è¯¯: {response.status_code} - {response.text[:100]}")
            return None

async def vectorize_document(file_path, config, db):
    """å‘é‡åŒ–å•ä¸ªæ–‡æ¡£"""
    print(f"\nğŸ“ å¤„ç†: {file_path.name}")
    
    # è¯»å–å†…å®¹
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    document_title = file_path.name.replace('MinerU_markdown_', '').replace('.md', '')
    
    # æŒ‰è¡Œåˆ†å‰²å¹¶åˆå¹¶æˆåˆç†å¤§å°çš„å—
    lines = content.split('\n')
    chunks = []
    current_chunk = ""
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # å¦‚æœå½“å‰å—åŠ ä¸Šæ–°è¡Œè¶…è¿‡800å­—ç¬¦ï¼Œä¿å­˜å½“å‰å—
        if len(current_chunk) + len(line) > 800:
            if len(current_chunk) > 100:  # åªä¿å­˜å¤§äº100å­—ç¬¦çš„å—
                chunks.append(current_chunk)
            current_chunk = line
        else:
            current_chunk += "\n" + line if current_chunk else line
    
    # ä¿å­˜æœ€åä¸€ä¸ªå—
    if len(current_chunk) > 100:
        chunks.append(current_chunk)
    
    print(f"  åˆ›å»º {len(chunks)} ä¸ªæ–‡æœ¬å—")
    
    # å¤„ç†æ¯ä¸ªå—
    success_count = 0
    for i, chunk_text in enumerate(chunks[:20]):  # å…ˆå¤„ç†å‰20ä¸ªå—æµ‹è¯•
        try:
            # æ£€æŸ¥é•¿åº¦
            if len(chunk_text.strip()) < 50:
                continue
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            from sqlalchemy import select
            text_hash = hashlib.sha256(chunk_text.encode()).hexdigest()
            stmt = select(KnowledgeBaseChunk).where(
                KnowledgeBaseChunk.chunk_text_hash == text_hash
            )
            result = await db.execute(stmt)
            if result.scalar_one_or_none():
                continue
            
            # ç”ŸæˆåµŒå…¥
            embedding = await generate_embedding(chunk_text, config)
            if not embedding:
                continue
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            kb_chunk = KnowledgeBaseChunk(
                id=uuid.uuid4(),
                source_type='disease_guideline',
                disease_id=uuid.uuid4(),
                disease_category='respiratory',
                document_title=document_title,
                section_title=f"Section_{i}",
                chunk_index=i,
                chunk_text=chunk_text[:2000],  # é™åˆ¶é•¿åº¦
                chunk_text_hash=text_hash,
                embedding=embedding,
                embedding_model_id=config.model_id,
                is_active=True,
                created_at=datetime.utcnow()
            )
            db.add(kb_chunk)
            await db.commit()
            
            success_count += 1
            if success_count % 5 == 0:
                print(f"  âœ… å·²å¤„ç† {success_count} ä¸ªå—")
                
        except Exception as e:
            print(f"  âŒ å— {i} å¤„ç†å¤±è´¥: {e}")
            await db.rollback()
    
    print(f"  âœ… å®Œæˆ: {success_count} ä¸ªå—å·²ä¿å­˜")

async def main():
    async with AsyncSessionLocal() as db:
        # è·å–é…ç½®
        from sqlalchemy import select
        stmt = select(VectorEmbeddingConfig).where(VectorEmbeddingConfig.is_active == True)
        result = await db.execute(stmt)
        config = result.scalar_one_or_none()
        
        if not config:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ´»è·ƒçš„Embeddingé…ç½®")
            return
        
        print(f"âœ… ä½¿ç”¨é…ç½®: {config.provider} / {config.model_id}")
        
        # æ–‡æ¡£ç›®å½•
        doc_dir = Path("/app/data/knowledge_bases/diseases/pediatric_bronchial_asthma")
        if not doc_dir.exists():
            print("âŒ æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨")
            return
        
        # å¤„ç†æ–‡æ¡£
        md_files = list(doc_dir.glob("*.md"))
        print(f"ğŸ“š æ‰¾åˆ° {len(md_files)} ä¸ªæ–‡æ¡£")
        
        for file_path in md_files[:1]:  # å…ˆå¤„ç†ç¬¬ä¸€ä¸ªæ–‡æ¡£
            await vectorize_document(file_path, config, db)
        
        print("\nğŸ‰ å¤„ç†å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())
